<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <meta charset="UTF-8">
    <link rel="shortcut icon" type="image/png" href="assets/icon/new-icon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>AAAI Fall Symposium | Speakers</title>
</head>

<body>

    <div class="hero">
    <img class="hero__img" src="assets/banner/editted-banner.jfif" alt="SECURE-AI4H Banner">
        <div class="hero__overlay">
            <div class="hero__content">
                <!-- Line 1: static (no typing, no cursor) -->
                <h1 class="hero__title">AAAI Fall Symposium &ndash; SECURE&#8209;AI4H</h1>

                <!-- Lines 2–4: typed sequentially with one caret per line -->
                <p class="hero__line type line2">
                    Safe, Ethical, Certified, Uncertainty-aware, Robust, and Explainable AI
                </p>
                <p class="hero__line type line3">November 6 &ndash; 8, 2025</p>
                <p class="hero__line type line4">Westin Arlington Gateway, VA</p>
            </div>
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Conference Home Page" href="index.html">Home</a>
            </td>
            <td class="navigation">
                <a title="Submit Papers" href="submissions/submissions.html">Call for Papers</a>
            </td>
            <td class="navigation">
                <a class="current" title="More Details" href="speakers/speakers.html">Speakers</a>
            </td>
            <td class="navigation">
                <a title="More Details" href="program/program.html">Program</a>
            </td>
            <td class="navigation">
                <a title="Venue" href="venue/venue.html">Venue</a> 
            </td>
            <td class="navigation">
                <a title="Register" href="registeration/register.html">Registration</a>
            </td>
        </tr>
    </table>

    <h2>Schedule</h2>
        <main class="container">
            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout single">
                    <div class="left-col">
                        <img class="avatar" src="assets/speakers/aidong-zhang.jfif" alt="Headshot of Presenter Name">

                        <div class="info">
                            <h3 class="speaker-name">Dr.Aidong Zhang</h3>
                            <p class="speaker-role">University of Virginia</p>
                            <p class="speaker-affil">Professor</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Explainable AI in Medical Imaging</h4>
                        <p class="talk-abstract">
                            In recent years, major advances in artificial intelligence (AI) have been applied to medical image diagnosis with promising results. 
                            Even though these methods demonstrate incredible potential for saving valuable person-hours and minimizing inadvertent human errors, their adoption has been met with rightful skepticism and extreme circumspection in critical applications such as medical diagnosis.
                            A paramount challenge is the lack of rationale behind predictions—making these systems notoriously “black boxes.” In extreme cases, this can create a mismatch between the designer’s intended behavior and the model’s actual performance.
                            In this talk, I will discuss our recent research on explainable AI strategies. 
                            In particular, I will describe concept-based learning models and show how both concept-based and example-based learning approaches can be designed for explainable deep neural networks, vision transformers, and vision-language models.
                        </p>
                    </div>
                </article>
            </section>
            
            <br>

            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout single">
                    <div class="left-col">
                        <img class="avatar" src="assets/speakers/Gamze Gursoy_headshot image.png" alt="Headshot of Presenter Name">

                        <div class="info">
                        <h3 class="speaker-name">Dr.Gamze Gürsoy</h3>
                        <p class="speaker-role">New York Genome Center, Columbia University</p>
                        <p class="speaker-affil">Assistant Professor</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Federated Learning Approaches to Biomedical Knowledge Discovery</h4>
                        <p class="talk-abstract">
                           The rapid expansion of omics technologies, coupled with the growing availability of structured medical records, creates unprecedented opportunities to deepen our understanding of health and disease. 
                           Yet these advances also raise formidable challenges: protecting patient privacy and enabling the integration of sensitive data across institutions. 
                           In this talk, I will present our lab’s work on privacy-preserving informatics and machine learning methods that enable critical biomedical analyses without requiring raw data to be centralized or shared. 
                           I will highlight techniques such as federated learning and secure multiparty computation that make it possible to discover new knowledge while maintaining strong privacy guarantees. 
                           Finally, I will discuss how standard federated learning often breaks down under real-world distributional shifts, and introduce novel approaches we have developed to address these limitations.
                        </p>
                    </div>
                </article>
            </section>


            <br>

            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <img class="avatar" src="assets\speakers\jonathan-takeshita.jpg" alt="Headshot of Presenter Name">

                        <div class="info">
                        <h3 class="speaker-name">Dr.Jonathan Takeshita</h3>
                        <p class="speaker-role">Assistant Professor</p>
                        <p class="speaker-affil">School of Cybersecurity, Old Dominion University</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Duty of Care: A Call for Open and Responsible AI Innovation in Healthcare</h4>
                        <p class="talk-abstract">
                        
                           Recent advances in AI, especially those of LLMs, bring the prospect of increased adoption of AI in medicine and medical education.
                            In particular, many institutions responsible for medical treatment and education are rapidly aiming to increase AI use in practice and curricula.
                            However, the potential downsides of overuse of AI in these fields are under-discussed.
                            In the rush to AI adoption, sources of healthcare risk such as LLM reliability, patient privacy, financial and environmental costs, vendor dependencies, and AI over-reliance are often not deeply considered.
                            This paper discusses these recent trends and makes recommendations for healthcare institutions considering further adoption of AI.                        
                        
                        </p>
                    </div>
                </article>
            </section>

            <br>

            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <img class="avatar" src="assets\speakers\philippe.jfif" alt="Headshot of Presenter Name">

                        <div class="info">
                            <h3 class="speaker-name">Dr. Philippe Giabbanelli</h3>
                            <p class="speaker-role">Professor</p>
                            <p class="speaker-affil">Old Dominion University</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization</h4>
                        <p class="talk-abstract">
                        
                            Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behaviors and physical activity behaviors. 
                            These models are potentially usable by different stakeholder groups, as they support policy-makers to estimate the consequences of potential interventions and they can guide individuals in making healthy choices in complex environments. 
                            However, this potential may not be fully realized because of the models' complexity, which makes them inaccessible to the stakeholders who could benefit the most. 
                            While Large Language Models (LLMs) can translate simulation outputs and the design of models into text, current approaches typically rely on one-size-fits-all summaries that fail to reflect the varied informational needs and stylistic preferences of clinicians, policymakers, patients, caregivers, and health advocates. 
                            This limitation stems from a fundamental gap: we lack a systematic understanding of what these stakeholders need from explanations and how to tailor them accordingly. 
                            To address this gap, we present a step-by-step to identify stakeholder needs and guide LLMs in generating tailored explanations of health simulations. 
                            Our procedure uses a mixed-methods design by first eliciting the explanation needs and stylistic preferences of diverse health stakeholders, then optimizing the ability of LLMs to generate tailored outputs (e.g., via controllable attribute tuning), and then evaluating through a comprehensive range of metrics to further improve the tailored generation of summaries. 
                        
                        </p>
                    </div>
                </article>
            </section>


            <br>

            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <img class="avatar" src="assets\speakers\igbal.jfif" alt="Headshot of Presenter Name">

                        <div class="info">
                            <h3 class="speaker-name">Dr. Mohammad Iqbal Nouyed</h3>
                            <p class="speaker-role"></p>
                            <p class="speaker-affil">West Virginia University Health Science</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Sensing without Alerting: The People-Pleaser Cost of General-Purpose Chatbots in Dermatology Patients with Psych Comorbidity</h4>
                        <p class="talk-abstract">
                        
                            Chatbots use may introduce psychiatric safety risks due to the people-pleasing design of these applications. 
                            Skin disease patients frequently experience anxiety and depression, and in some cases, these symptoms may indicate an underlying psychotic disorder. 
                            When such individuals seek emotional support from general-purpose chatbots, their response may heighten distress if mental-health concerns are not detected and appropriately triaged. 
                            We evaluated ChatGPT-5 (October 2025) for its ability to (i) flag potential mental-health issues and recommend follow-up with (ii) dermatology and (iii) psychiatry specialists. 
                            27 first-person disease narratives were generated from published case reports involving skin complaints with varying degrees of concurrent psychiatric condition. 
                            Each case was structured into sections and presented to the chatbot sequentially. ChatGPT raised mental-health concerns in 65.3 ± 2.3% of cases. Dermatology referrals were common (94.7%), whereas psychiatry referrals were infrequent (17.3 ± 10.1%). 
                            Among the 8 cases a board-certified psychiatrist judged as urgently needing help, only 12.3 ± 6.1% were recommended to be referred to a mental health provider. 
                            Future chatbot development should strengthen guardrails that prioritize user safety, including prompting timely mental-health referral when risk cues are present. 
                        
                        </p>
                    </div>
                </article>
            </section>


            <br>


            
            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <img class="avatar" src="assets\speakers\gangqin-hu.jfif" alt="Headshot of Presenter Name">

                        <div class="info">
                            <h3 class="speaker-name">Dr. Gangqin Hu</h3>
                            <p class="speaker-role">Assistant Professor</p>
                            <p class="speaker-affil">West Virginia University</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Dermatologic Image Analysis with ChatGPT: the Good, the Bad, and the Ugly.</h4>
                        <p class="talk-abstract">
                            Multimodal LLMs like ChatGPT can assist dermatologic image understanding with few‑shot learning (Good), yet baseline performance remains limited (Bad), and popular deployment paths (e.g., custom GPTs) show technical and security limitations (Ugly).
                        </p>
                    </div>
                </article>
            </section>

            <br>


            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <img class="avatar" src="assets\speakers\apurva-ratan.jfif" alt="Headshot of Presenter Name">

                        <div class="info">
                            <h3 class="speaker-name">Dr. Apurv Ratan Murty</h3>
                            <p class="speaker-role">Assistant Professor</p>
                            <p class="speaker-affil">Georgia Institute of Technology</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Title: TBD</h4>
                        <p class="talk-abstract">
                            Abstract: TBD
                        </p>
                    </div>
                </article>
            </section>

            <br>

            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <img class="avatar" src="assets\speakers\quingyu chen.jfif" alt="Headshot of Presenter Name">

                        <div class="info">
                            <h3 class="speaker-name">Dr. Qingyu Chen</h3>
                            <p class="speaker-role">Assistant Professor</p>
                            <p class="speaker-affil">North Carolina A&amp;T State University</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Title: TBD</h4>
                        <p class="talk-abstract">
                            Abstract: TBD
                        </p>
                    </div>
                </article>
            </section>

            <br>

            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card side-layout">
                    <div class="left-col">
                        <div class="avatar-fallback">S K</div>

                        <div class="info">
                            <h3 class="speaker-name">Salamata Konate</h3>
                            <p class="speaker-role">Postdoc Researcher</p>
                            <p class="speaker-affil">Lassonde School of Engineering, York University</p>
                        </div>
                    </div>

                    <div class="right-col">
                        <h4 class="talk-title">Tile: TBD</h4>
                        <p class="talk-abstract">
                            Abstract: TBD
                        </p>
                    </div>
                </article>
            </section>

            <br>


            <section class="speakers-grid" id="speakersGrid">
                <article class="speaker-card diag-duo v2" id="talk-xyz">
                    <!-- Left column: shared diagonal frame -->
                    <div class="media">
                        <!-- Initial diagonal split (shown when NOT hovering) -->
                        <div class="split">
                        <img class="img img-a" src="assets\speakers\xia-tian.avif" alt="Presenter A">
                        <img class="img img-b" src="assets\speakers\mehran.avif" alt="Presenter B">
                        <span class="diag-line" aria-hidden="true"></span>
                        </div>

                        <!-- Full-frame layers (shown while hovering; crossfade A <-> B) -->
                        <img class="full full-a" src="assets\speakers\xia-tian.avif" alt="" aria-hidden="true">
                        <img class="full full-b" src="assets\speakers\mehran.avif" alt="" aria-hidden="true">
                    </div>

                    <!-- Under the frame: single-line label -->
                    <div class="inst-rotator" aria-live="polite">
                        <div class="inst inst-default" title="Institute A &amp; Institute B">Sanford Burnham Prebys Medical Discovery Institute</div>
                        <div class="inst inst-a" title="Presenter A — Role A">Xia Tian — Assistant Professor</div>
                        <div class="inst inst-b" title="Presenter B — Role B">Mehran Ghafari — Postdoctoral Associate</div>
                    </div>

                    <!-- Right column: spans full height on the right -->
                    <div class="content">
                        <h4 class="talk-title">Real-Time, Non-Invasive Monitoring of Energy Expenditure to Evaluate Physiological Aging in Mice</h4>
                        <p class="talk-abstract">
                        Accurate assessment of aging-related physiological changes requires tools that minimize stress and reflect natural behaviors. 
                        In this talk, I will present a real-time, non-invasive monitoring platform that uses thermal imaging to continuously track energy expenditure, motor activity, and circadian rhythm in mice within their home cages. 
                        This system enables long-term observation under naturalistic conditions and avoids the confounding effects of forced tasks or handling stress. 
                        Our findings reveal consistent differences between young and aged mice, demonstrating the platform’s sensitivity to subtle age-related decline. 
                        This approach offers significant potential for studying the progression of age-related diseases and evaluating early-stage interventions in preclinical models.
                        </p>
                    </div>
                </article>
            </section>


            <br>
            


            

    

        </main>

</body>
</html>

